# =============================================================
# ‚ö° MimicVerse Cache Models Utility (v1.0)
# Purpose: Pre-download & warm up all heavy models safely
# Compatible with Streamlit Cloud + GitHub Actions
# =============================================================

import os
import spacy
from sentence_transformers import SentenceTransformer
from keybert import KeyBERT
from transformers import pipeline

print("üöÄ Starting model cache process...")

# ---------- 1. SpaCy Model ----------
try:
    print("üß† Downloading spaCy model...")
    spacy.cli.download("en_core_web_sm")
    nlp = spacy.load("en_core_web_sm")
    print("‚úÖ spaCy model ready.")
except Exception as e:
    print(f"‚ö†Ô∏è spaCy error: {e}")

# ---------- 2. SentenceTransformer ----------
try:
    print("üß† Loading SentenceTransformer (MiniLM)...")
    st_model = SentenceTransformer("all-MiniLM-L6-v2")
    print("‚úÖ SentenceTransformer cached.")
except Exception as e:
    print(f"‚ö†Ô∏è ST error: {e}")

# ---------- 3. KeyBERT ----------
try:
    print("üß† Initializing KeyBERT with MiniLM...")
    kw_model = KeyBERT(model=st_model)
    print("‚úÖ KeyBERT model cached.")
except Exception as e:
    print(f"‚ö†Ô∏è KeyBERT error: {e}")

# ---------- 4. Summarization Pipeline ----------
try:
    print("üß† Preloading summarizer (BART)...")
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    print("‚úÖ Summarizer cached.")
except Exception as e:
    print(f"‚ö†Ô∏è Summarizer error: {e}")

# ---------- 5. Confirmation Marker ----------
os.makedirs("models_cache", exist_ok=True)
with open("models_cache/info.txt", "w") as f:
    f.write("‚úÖ Models cached successfully.\n")

print("\nüéâ All models are prewarmed and ready to serve!")